{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0XfGrXK9u2Q"
   },
   "source": [
    "\n",
    "\n",
    "<h1 align=\"center\"> Fake Reddit Prediction </h1>\n",
    "<h2 align=\"center\"> Competition #3 </h2>\n",
    "\n",
    "\n",
    "\n",
    "# **Name:**  Sandra Girgis\n",
    "# **ID:** 20399121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GIOJDR42_nW"
   },
   "source": [
    "# **Problem Statement**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "☘️ The problem of the fake Reddit prediction by looking only at the title is the difficulty in determining the authenticity and accuracy of the information presented in the title alone. The title of a Reddit post may be misleading or sensationalized, leading to false assumptions or conclusions about the content of the post. This can result in misinformation being spread and can also cause confusion and distrust among Reddit users that it is caused by several things such as:\n",
    "\n",
    "*   Misinformation: Fake predictions can spread false information, leading to confusion and misinformation among users. This can result in users making poor decisions based on inaccurate data or beliefs.\n",
    " Therefore, it is important to carefully evaluate the content of a post before accepting it as true, even if the title appears to be accurate or reliable.\n",
    "\n",
    "*   Manipulation: Users who create fake predictions may have ulterior motives, such as financial gain or promoting a particular agenda. By spreading false predictions, they can manipulate public opinion or market behavior to their advantage.\n",
    "\n",
    "*   Wasted Resources: Users who spend time and effort engaging with, debunking, or researching fake predictions are utilizing resources that could be better spent on more productive activities.\n",
    "\n",
    "\n",
    "*   Distrust: The prevalence of fake predictions can lead to an erosion of trust in the platform and its users. When it becomes difficult to differentiate between genuine insights and fabricated claims, users may become skeptical of all information shared on the platform.\n",
    "\n",
    "\n",
    "So, it is important to carefully evaluate the content of a post before accepting it as true, even if the title appears to be accurate or reliable.\n",
    "\n",
    "\n",
    "### 👉🏻 Therefore, the best solution to this problem is that we adopt the Natural Language Processing (NLP) model and apply it to the data we have in order to be able to know whether that address is fake or not.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONqVcyG4_7le"
   },
   "source": [
    "⭐ **The input of the Reddit Fake Post Detection (by Looking Only at the Title) project would be** a set of Reddit post. The goal of the project is to develop a machine learning model that can accurately classify whether a post title is fake or real based solely on its wording. Therefore, the input data would consist of a collection of post that have been labeled as either fake or real, which would be used to train and test the model.\n",
    "\n",
    "⭐ **The output is** the identification of fake or inaccurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ajgVwfuPAez"
   },
   "source": [
    "☘️  **The data mining function required for the case of Reddit Fake Post Detection,** is text Prediction function would be used to predict the titles as either genuine or fake based on the content of the title. This would involve some preprocessing techniquesthe to clean the text such as:\n",
    "* Remove stop words, \n",
    "* Tokenization   \n",
    "* Text Normalization\n",
    "* Stemming or lemmatizing the words, \n",
    "* Converting the text into a numerical format that can be processed by machine learning algorithms.\n",
    "\n",
    "👉🏻 In this problem we wil use most of these techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN8QXSYeE3LM"
   },
   "source": [
    "### ☘️ **There are several challenges of the Reddit Fake Post Detection by looking only at the title:**\n",
    "\n",
    "Ambiguity: Titles can be ambiguous and can have multiple meanings. It can be difficult to determine the intention of the user when they create a post title, and it may not always be clear whether the title is intentionally misleading or not.\n",
    "\n",
    "Satire and sarcasm: Some posts may use satire or sarcasm in their titles to make a point or to be humorous. This can make it difficult to distinguish between fake and genuine posts, as some fake posts may be intended as satire or sarcasm.\n",
    "\n",
    "Context: Titles often lack context, and it can be difficult to determine the full meaning of a post based solely on its title. It is possible that a post with a misleading or clickbait title may contain genuine information or discussion once the full context is considered.\n",
    "\n",
    "Creativity: Users can be creative and come up with novel ways to create misleading or clickbait titles that may not be caught by a simple detection algorithm. This may require more sophisticated techniques to accurately detect fake posts.\n",
    "\n",
    "Language: Titles can be written in different languages or use slang and colloquialisms that may not be easily understood by a detection algorithm. This can make it challenging to accurately detect fake posts across different languages and cultures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6vIdlZ2E8ms"
   },
   "source": [
    "### ☘️ **The impact has two aspects:**\n",
    "\n",
    "⭐ **First: The impact of this problem on the validity, accuracy and credibility of choosing the title:**\n",
    "\n",
    "The impact of the Reddit Fake Post Detection (by looking only at the title) would depend on the effectiveness of the approach. In general, it is likely to have limited accuracy, as it is relatively easy to create misleading or clickbait titles that do not accurately reflect the content of a post. However, it could still be a useful tool for flagging potentially problematic posts for further review.\n",
    "\n",
    "⭐ **Second: The impact of applying the Natural Languag Processing model on these data:**\n",
    "\n",
    "Using an NLP model to solve this problem could have a much larger impact, as it would allow for a more sophisticated analysis of the language used in the post title and potentially the full post. NLP models can be trained to detect patterns that are indicative of fake or misleading content, such as the use of emotionally charged language or the omission of key details. By using an NLP model, it would be possible to detect fake posts with greater accuracy and efficiency, potentially reducing the spread of misinformation and improving the overall quality of online discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iI05-PeCBz8d"
   },
   "source": [
    "☘️ **The optimal solution of this problem** may include the use of machine learning algorithms to analyze the text and identify the pattern, and as we mentioned before, the application of Natural Language Processing (NLP) will help us in this.\n",
    "So;\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) that deals with the interaction between computers and human language. It involves the development of algorithms and techniques that enable machines to understand, interpret, and generate natural language text or speech.\n",
    "\n",
    "NLP involves a variety of tasks such as text classification, sentiment analysis, named entity recognition, machine translation, and text summarization. It utilizes techniques from various fields such as linguistics, computer science, and statistics to process and analyze large amounts of natural language data.\n",
    "\n",
    "NLP has many practical applications, including language translation, chatbots, voice assistants, content analysis, and sentiment analysis. With the advancement of deep learning and neural networks, NLP has made significant strides in recent years, and its applications continue to grow in various industries such as healthcare, finance, and marketing.\n",
    "\n",
    "#### **👉🏻 So let's work on the data available to us, and we will see in this notebook how the linguistic word processing model is applied to the data we have, and see what is the accurate solution out of all the solutions presented in this notebook...😃**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9RaJXbr4J-w"
   },
   "source": [
    "# **Part I: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GKtB8Qt0hfOk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\lap1\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\lap1\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.22.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\lap1\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\lap1\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\lap1\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\lap1\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\lap1\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lap1\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lap1\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lap1\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lap1\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lap1\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lap1\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lap1\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8StLXSKVzy94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.1.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# some seeting for pandas and hvplot\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 300\n",
    "pd.options.display.max_colwidth = 100\n",
    "np.set_printoptions(threshold=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FFZtxco144yZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('all')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from skopt import gp_minimize\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "TMdB6kFl45um"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265723</td>\n",
       "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284269</td>\n",
       "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207715</td>\n",
       "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551106</td>\n",
       "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8584</td>\n",
       "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>70046</td>\n",
       "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>189377</td>\n",
       "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>93486</td>\n",
       "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>140950</td>\n",
       "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>34509</td>\n",
       "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  \\\n",
       "0      265723   \n",
       "1      284269   \n",
       "2      207715   \n",
       "3      551106   \n",
       "4        8584   \n",
       "...       ...   \n",
       "59995   70046   \n",
       "59996  189377   \n",
       "59997   93486   \n",
       "59998  140950   \n",
       "59999   34509   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
       "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
       "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
       "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
       "4      Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
       "...                                                                                                    ...   \n",
       "59995                Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
       "59996                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
       "59997                Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
       "59998                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
       "59999                Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "59995      0  \n",
       "59996      1  \n",
       "59997      0  \n",
       "59998      0  \n",
       "59999      1  \n",
       "\n",
       "[60000 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read raw data\n",
    "train_data = pd.read_csv(\"xy_train.csv\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "acFdhJKRFJMX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stargazer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Believers\" - Hezbollah 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59146</th>\n",
       "      <td>59146</td>\n",
       "      <td>Bicycle taxi drivers of New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59147</th>\n",
       "      <td>59147</td>\n",
       "      <td>Trump blows up GOP's formula for winning House races</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59148</th>\n",
       "      <td>59148</td>\n",
       "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59149</th>\n",
       "      <td>59149</td>\n",
       "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59150</th>\n",
       "      <td>59150</td>\n",
       "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59151 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "0          0   \n",
       "1          1   \n",
       "2          2   \n",
       "3          3   \n",
       "4          4   \n",
       "...      ...   \n",
       "59146  59146   \n",
       "59147  59147   \n",
       "59148  59148   \n",
       "59149  59149   \n",
       "59150  59150   \n",
       "\n",
       "                                                                                  text  \n",
       "0                                                                           stargazer   \n",
       "1                                                                                 yeah  \n",
       "2                           PD: Phoenix car thief gets instructions from YouTube video  \n",
       "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility  \n",
       "4                                                         \"Believers\" - Hezbollah 2011  \n",
       "...                                                                                ...  \n",
       "59146                                                Bicycle taxi drivers of New Delhi  \n",
       "59147                             Trump blows up GOP's formula for winning House races  \n",
       "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised  \n",
       "59149                                 Deep down he always wanted to be a ballet dancer  \n",
       "59150                        Toddler miraculously survives 6-story fall landing on car  \n",
       "\n",
       "[59151 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read raw data\n",
    "test_data = pd.read_csv(\"x_test.csv\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxOk6s1yo4cK"
   },
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1hlIIDeeTyQZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32172\n",
       "1    27596\n",
       "2      232\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "HhKotjtsWXsN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32172\n",
       "1    27596\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unconsistence values\n",
    "train_data.drop(train_data[(train_data['label'] == 2)].index , inplace=True)\n",
    "train_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "igqeLsHGppdz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    59768\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Null Values in training set\n",
    "train_data[\"text\"].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "a2Z3oUUYqMpZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id      0\n",
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "LPkA17ykp1a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    59151\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Null Values in Testing set\n",
    "test_data[\"text\"].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "_vhARf202_nc"
   },
   "outputs": [],
   "source": [
    "# y_train.fillna(\"IGNORE TEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "HNeQnxrq84M9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lap1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lap1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "d8FByeA8ukDL"
   },
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "DKQqtjrAlM-Q"
   },
   "outputs": [],
   "source": [
    "# Cleaning Function\n",
    "def clean_text(text, for_embedding=False):\n",
    "    \"\"\" steps:\n",
    "        - remove any html tags (< /br> often found)\n",
    "        - Keep only ASCII + European Chars and whitespace, no digits\n",
    "        - remove single letter chars\n",
    "        - convert all whitespaces (tabs etc.) to single wspace\n",
    "        if not for embedding (but e.g. tdf-idf):\n",
    "        - all lowercase\n",
    "        - remove stopwords, punctuation and stemm\n",
    "    \"\"\"\n",
    "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
    "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
    "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
    "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž0-9]\\b\", re.IGNORECASE)\n",
    "    RE_DIGITS = re.compile(r'W*dw*', re.IGNORECASE)\n",
    "    RE_LINKS = re.compile(r\"https://\\S+|www\\.\\S+\", re.IGNORECASE)\n",
    "\n",
    "    text = re.sub(RE_TAGS, \" \", text)\n",
    "    text = re.sub(RE_ASCII, \" \", text)\n",
    "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
    "    text = re.sub(RE_WSPACE, \" \", text)\n",
    "    text = re.sub(RE_DIGITS, \" \", text)\n",
    "    # text = re.sub(RE_LINKS, \" \", text)\n",
    "\n",
    "    word_tokens = word_tokenize(text)\n",
    "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
    "\n",
    "\n",
    "    words_filtered = [\n",
    "        stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
    "        ]\n",
    "\n",
    "    text_clean = \" \".join(words_filtered)\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "JBNs7AbcGCMo"
   },
   "outputs": [],
   "source": [
    "#Lemmatize the dataset\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def lemma_traincorpus(data):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    out_data=\"\"\n",
    "    for words in data:\n",
    "        out_data+= lemmatizer.lemmatize(words)\n",
    "    return out_data\n",
    "\n",
    "train_data['text']=train_data['text'].apply(lambda z: lemma_traincorpus(z) if isinstance(z, str) else z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "csAZkDS2vP5N"
   },
   "outputs": [],
   "source": [
    "#Lemmatize the dataset\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def lemma_traincorpus(data):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    out_data=\"\"\n",
    "    for words in data:\n",
    "        out_data+= lemmatizer.lemmatize(words)\n",
    "    return out_data\n",
    "\n",
    "test_data['text']=test_data['text'].apply(lambda z: lemma_traincorpus(z) if isinstance(z, str) else z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "IsRixIBkrPBI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Clean text\n",
    "train_data[\"text\"] = train_data.loc[train_data[\"text\"].str.len() > 20, \"text\"]\n",
    "train_data[\"text\"] = train_data[\"text\"].map(\n",
    "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "3dZs4xW3FR4P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Clean text\n",
    "test_data[\"text\"] = test_data.loc[test_data[\"text\"].str.len() > 0, \"text\"]\n",
    "test_data[\"text\"] = test_data[\"text\"].map(\n",
    "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "4saUbzDwJKWP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265723</td>\n",
       "      <td>group frien began volunt homeless shelter neighbor protest see anoth person also nee shoul natur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284269</td>\n",
       "      <td>british prime minist theresa may nerv attack former russian spi govern conclu e high like russia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207715</td>\n",
       "      <td>goo year releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish mi atlant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551106</td>\n",
       "      <td>happi birth ay bob barker price right host like remember man sai ave pet spay neuter fuckincorpo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8584</td>\n",
       "      <td>obama nation innoc cop unarm young black men shoul ying magic johnson jimbobshawobo ob olymp ath...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>70046</td>\n",
       "      <td>finish sniper simo yh ure invas finlan ussr color</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>189377</td>\n",
       "      <td>nigerian princ scam took kansa man year later get back</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>93486</td>\n",
       "      <td>safe smoke marijuana ure pregnanc surpris answer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>140950</td>\n",
       "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>34509</td>\n",
       "      <td>jeff bri ges releas leep tape new album esign help fall asleep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  \\\n",
       "0      265723   \n",
       "1      284269   \n",
       "2      207715   \n",
       "3      551106   \n",
       "4        8584   \n",
       "...       ...   \n",
       "59995   70046   \n",
       "59996  189377   \n",
       "59997   93486   \n",
       "59998  140950   \n",
       "59999   34509   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0      group frien began volunt homeless shelter neighbor protest see anoth person also nee shoul natur...   \n",
       "1      british prime minist theresa may nerv attack former russian spi govern conclu e high like russia...   \n",
       "2      goo year releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish mi atlant...   \n",
       "3      happi birth ay bob barker price right host like remember man sai ave pet spay neuter fuckincorpo...   \n",
       "4      obama nation innoc cop unarm young black men shoul ying magic johnson jimbobshawobo ob olymp ath...   \n",
       "...                                                                                                    ...   \n",
       "59995                                                    finish sniper simo yh ure invas finlan ussr color   \n",
       "59996                                               nigerian princ scam took kansa man year later get back   \n",
       "59997                                                     safe smoke marijuana ure pregnanc surpris answer   \n",
       "59998                                               julius caesar upon realiz everyon room knife except bc   \n",
       "59999                                       jeff bri ges releas leep tape new album esign help fall asleep   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "59995      0  \n",
       "59996      1  \n",
       "59997      0  \n",
       "59998      0  \n",
       "59999      1  \n",
       "\n",
       "[59768 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "KuwZEJJCq_eJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "er          4255\n",
       "year        4133\n",
       "ing         3973\n",
       "ay          3969\n",
       "one         3647\n",
       "like        3129\n",
       "new         2998\n",
       "look        2847\n",
       "man         2845\n",
       "color       2738\n",
       "get         2715\n",
       "trump       2582\n",
       "ent         2570\n",
       "ol          2444\n",
       "say         2356\n",
       "peopl       2316\n",
       "use         2307\n",
       "first       2249\n",
       "make        2227\n",
       "foun        2214\n",
       "time        2033\n",
       "poster      2000\n",
       "en          1919\n",
       "war         1894\n",
       "ure         1835\n",
       "go          1726\n",
       "post        1649\n",
       "ha          1647\n",
       "worl        1637\n",
       "th          1580\n",
       "life        1550\n",
       "us          1545\n",
       "work        1533\n",
       "show        1513\n",
       "american    1505\n",
       "take        1500\n",
       "psbattl     1470\n",
       "presi       1469\n",
       "see         1456\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.models import NumeralTickFormatter\n",
    "# Word Frequency of most common words\n",
    "word_freq = pd.Series(\" \".join(train_data[\"text\"]).split()).value_counts()\n",
    "word_freq[1:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbpIsVd3LtUX"
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "EB0QLiK3igOc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" checked><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign TF-IDF Vsctorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))\n",
    "vectorizer.fit(train_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "wpdjMbHqMSB-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique word (ngram) vector extract:\n",
      "\n",
      " repli               7633\n",
      "hurrican florenc    4080\n",
      "late night          4933\n",
      "creation            2073\n",
      "rail                7405\n",
      "crie                2086\n",
      "superior            8964\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vector representation of vocabulary show some sample from our data_clean\n",
    "word_vector = pd.Series(vectorizer.vocabulary_).sample(7, random_state=1) \n",
    "print(f\"Unique word (ngram) vector extract:\\n\\n {word_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "RegRnmy_NzJX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47814,)\n",
      "(59151,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(train_data, random_state=1, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_train = train[\"text\"]\n",
    "y_train = train[\"label\"]\n",
    "X_test = test_data['text']\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd2sJxGaOxI2"
   },
   "source": [
    "# Creating Pipeline & Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAF21A4K1uxo"
   },
   "source": [
    "## I) Word-Level Victorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHRsXXTUO46V"
   },
   "source": [
    "### Model#1 XGB with Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "CWqXQZtg2_ne"
   },
   "outputs": [],
   "source": [
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    X_train, y_train, train_size = 0.8, stratify = y_train, random_state = 2022)\n",
    "\n",
    "# Create a list where train data indices are -1 and validation data indices are 0\n",
    "# X_train2 (new training set), X_train\n",
    "split_index = [-1 if x in X_train2.index else 0 for x in X_train.index]\n",
    "\n",
    "# Use the list to create PredefinedSplit\n",
    "pds = PredefinedSplit(test_fold = split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "u954weqkOsCt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;XGB&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature_types=None,\n",
       "                                                            gam...\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;XGB&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature_types=None,\n",
       "                                                            gam...\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;XGB&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                             ('XGB',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature_types=None,\n",
       "                                                            gam...\n",
       "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"XGB\", XGBClassifier())])\n",
    "\n",
    "# define parameter space to test # runtime 35min\n",
    "params = {\n",
    "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "    'XGB__min_child_weight': [20,40,80],\n",
    "    'XGB__max_depth':[50,60,70],  \n",
    "    'XGB__gamma':[0.5, 1, 1.5, 2, 5]\n",
    "}\n",
    "pipe_XGB_Random = RandomizedSearchCV(\n",
    "    pipe, params, cv=pds, n_jobs=-1, scoring='roc_auc', n_iter=10)\n",
    "pipe_XGB_Random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "9SzM6t6qQ5zm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 48, 'tfidf__max_df': 0.3, 'XGB__min_child_weight': 20, 'XGB__max_depth': 50, 'XGB__gamma': 5}\n"
     ]
    }
   ],
   "source": [
    "# Getting The Best Parameter of the model\n",
    "best_params_XGB_Random = pipe_XGB_Random.best_params_\n",
    "print(best_params_XGB_Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "NDMbr98iQ-hE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      5151\n",
      "           1       0.79      0.79      0.79      4412\n",
      "\n",
      "    accuracy                           0.81      9563\n",
      "   macro avg       0.81      0.81      0.81      9563\n",
      "weighted avg       0.81      0.81      0.81      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_XGB_Random).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdThCi1wRTfN"
   },
   "outputs": [],
   "source": [
    "# Use this cell to write the result in the excel sheet.\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['id'] = test_data['id']\n",
    "\n",
    "submission['label'] = pipe_XGB_Random.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission.to_csv('trial01_XGB_Random_word_clean_72.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpPy02CISgMi"
   },
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Word-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using XGBClassifier with Random Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 81%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * ngram_range: (1, 3)\n",
    "  * min_df: 48\n",
    "  * max_df: 0.3\n",
    "  * min_child_weight: 20\n",
    "  * max_depth: 50\n",
    "  * gamma: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsGwjwhpSo53"
   },
   "source": [
    "### Model#2 XGB with Bayes Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "cYRgduo5Swq1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                        (&#x27;XGB&#x27;,\n",
       "                                         XGBClassifier(base_score=None,\n",
       "                                                       booster=None,\n",
       "                                                       callbacks=None,\n",
       "                                                       colsample_bylevel=None,\n",
       "                                                       colsample_bynode=None,\n",
       "                                                       colsample_bytree=None,\n",
       "                                                       early_stopping_rounds=None,\n",
       "                                                       enable_categorical=False,\n",
       "                                                       eval_metric=None,\n",
       "                                                       feature_types=None,\n",
       "                                                       gamma=No...\n",
       "                             &#x27;XGB__min_child_weight&#x27;: [20, 40, 80],\n",
       "                             &#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                        (&#x27;XGB&#x27;,\n",
       "                                         XGBClassifier(base_score=None,\n",
       "                                                       booster=None,\n",
       "                                                       callbacks=None,\n",
       "                                                       colsample_bylevel=None,\n",
       "                                                       colsample_bynode=None,\n",
       "                                                       colsample_bytree=None,\n",
       "                                                       early_stopping_rounds=None,\n",
       "                                                       enable_categorical=False,\n",
       "                                                       eval_metric=None,\n",
       "                                                       feature_types=None,\n",
       "                                                       gamma=No...\n",
       "                             &#x27;XGB__min_child_weight&#x27;: [20, 40, 80],\n",
       "                             &#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;XGB&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                        ('XGB',\n",
       "                                         XGBClassifier(base_score=None,\n",
       "                                                       booster=None,\n",
       "                                                       callbacks=None,\n",
       "                                                       colsample_bylevel=None,\n",
       "                                                       colsample_bynode=None,\n",
       "                                                       colsample_bytree=None,\n",
       "                                                       early_stopping_rounds=None,\n",
       "                                                       enable_categorical=False,\n",
       "                                                       eval_metric=None,\n",
       "                                                       feature_types=None,\n",
       "                                                       gamma=No...\n",
       "                             'XGB__min_child_weight': [20, 40, 80],\n",
       "                             'tfidf__max_df': array([0.3]),\n",
       "                             'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"XGB\", XGBClassifier())])\n",
    "\n",
    "# define parameter space to test # runtime 35min\n",
    "params = {\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "    'XGB__min_child_weight': [20,40,80],\n",
    "    'XGB__max_depth':[50,60,70],  \n",
    "    'XGB__gamma':[0.5, 1, 1.5, 2, 5]\n",
    "}\n",
    "# it is quite slow so we do 4 for now\n",
    "pipe_XGB_Bayes = BayesSearchCV(\n",
    "    pipe, params, cv=pds, n_jobs=-1, scoring='roc_auc', n_iter=10)\n",
    "pipe_XGB_Bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "xMxiFdbIULSm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('XGB__gamma', 1.5), ('XGB__max_depth', 50), ('XGB__min_child_weight', 20), ('tfidf__max_df', 0.3), ('tfidf__min_df', 62)])\n"
     ]
    }
   ],
   "source": [
    "# Getting The Best Parameter of the model\n",
    "best_params_XGB_Bayes = pipe_XGB_Bayes.best_params_\n",
    "print(best_params_XGB_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "_hx3boosUXmN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      5151\n",
      "           1       0.83      0.81      0.82      4412\n",
      "\n",
      "    accuracy                           0.83      9563\n",
      "   macro avg       0.83      0.83      0.83      9563\n",
      "weighted avg       0.83      0.83      0.83      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_XGB_Bayes).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMJNu7L9UcsF"
   },
   "outputs": [],
   "source": [
    "# Use this cell to write the result in the excel sheet.\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['id'] = test_data['id']\n",
    "\n",
    "submission['label'] = pipe_XGB_Bayes.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission.to_csv('trial02_XGB_Bayes_word_clean_71.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Word-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using XGBClassifier with Bayse Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 83%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * min_df: 62\n",
    "  * max_df: 0.3\n",
    "  * min_child_weight: 20\n",
    "  * max_depth: 50\n",
    "  * gamma: 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAFMZJisU1tl"
   },
   "source": [
    "### Model#3 MLP with Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "qUC90G-3U6ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;MLP&#x27;,\n",
       "                                              MLPClassifier(hidden_layer_sizes=(15,\n",
       "                                                                                15,\n",
       "                                                                                15),\n",
       "                                                            learning_rate=&#x27;adaptive&#x27;,\n",
       "                                                            random_state=1))]),\n",
       "                   n_jobs=2,\n",
       "                   param_distributions={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;MLP&#x27;,\n",
       "                                              MLPClassifier(hidden_layer_sizes=(15,\n",
       "                                                                                15,\n",
       "                                                                                15),\n",
       "                                                            learning_rate=&#x27;adaptive&#x27;,\n",
       "                                                            random_state=1))]),\n",
       "                   n_jobs=2,\n",
       "                   param_distributions={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;MLP&#x27;,\n",
       "                 MLPClassifier(hidden_layer_sizes=(15, 15, 15),\n",
       "                               learning_rate=&#x27;adaptive&#x27;, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(15, 15, 15), learning_rate=&#x27;adaptive&#x27;,\n",
       "              random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                             ('MLP',\n",
       "                                              MLPClassifier(hidden_layer_sizes=(15,\n",
       "                                                                                15,\n",
       "                                                                                15),\n",
       "                                                            learning_rate='adaptive',\n",
       "                                                            random_state=1))]),\n",
       "                   n_jobs=2,\n",
       "                   param_distributions={'tfidf__max_df': array([0.3]),\n",
       "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
       "                   scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"MLP\",  MLPClassifier(\n",
    "        random_state=1,\n",
    "        solver=\"adam\",\n",
    "        hidden_layer_sizes=(15, 15, 15),\n",
    "        activation=\"relu\",\n",
    "        alpha=0.0001,\n",
    "        learning_rate= 'adaptive',\n",
    "    ))])\n",
    "\n",
    "# define parameter space to test\n",
    "params = {\n",
    "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "}\n",
    "\n",
    "pipe_MLP_Random = RandomizedSearchCV(\n",
    "    pipe, params, cv=pds, verbose=1, n_jobs=2, scoring='roc_auc')\n",
    "\n",
    "# fit the pipeline\n",
    "pipe_MLP_Random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "bIMhWVWIVxO1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 16, 'tfidf__max_df': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# Getting The Best Parameter of the model\n",
    "best_params_MLP_Random = pipe_MLP_Random.best_params_\n",
    "print(best_params_MLP_Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "JeQbNofCXpIe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5151\n",
      "           1       1.00      1.00      1.00      4412\n",
      "\n",
      "    accuracy                           1.00      9563\n",
      "   macro avg       1.00      1.00      1.00      9563\n",
      "weighted avg       1.00      1.00      1.00      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_MLP_Random).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQViXysfX2ud"
   },
   "outputs": [],
   "source": [
    "# Use this cell to write the result in the excel sheet.\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['id'] = test_data['id']\n",
    "\n",
    "submission['label'] = pipe_MLP_Random.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission.to_csv('trial03_MLP_Random_word_clean_74.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Word-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using MLPClassifier with Random Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 100%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * ngram_range: (1, 2)\n",
    "  * min_df: 16\n",
    "  * max_df: 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOt_IFV4YHfM"
   },
   "source": [
    "### Model#4 MLP with Bayes Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "hptb_xOqYUr0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                        (&#x27;MLP&#x27;,\n",
       "                                         MLPClassifier(early_stopping=True,\n",
       "                                                       hidden_layer_sizes=(12,\n",
       "                                                                           12,\n",
       "                                                                           12),\n",
       "                                                       learning_rate=&#x27;adaptive&#x27;,\n",
       "                                                       random_state=1))]),\n",
       "              n_jobs=2, scoring=&#x27;roc_auc&#x27;,\n",
       "              search_spaces={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                        (&#x27;MLP&#x27;,\n",
       "                                         MLPClassifier(early_stopping=True,\n",
       "                                                       hidden_layer_sizes=(12,\n",
       "                                                                           12,\n",
       "                                                                           12),\n",
       "                                                       learning_rate=&#x27;adaptive&#x27;,\n",
       "                                                       random_state=1))]),\n",
       "              n_jobs=2, scoring=&#x27;roc_auc&#x27;,\n",
       "              search_spaces={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;MLP&#x27;,\n",
       "                 MLPClassifier(early_stopping=True,\n",
       "                               hidden_layer_sizes=(12, 12, 12),\n",
       "                               learning_rate=&#x27;adaptive&#x27;, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 12, 12),\n",
       "              learning_rate=&#x27;adaptive&#x27;, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                        ('MLP',\n",
       "                                         MLPClassifier(early_stopping=True,\n",
       "                                                       hidden_layer_sizes=(12,\n",
       "                                                                           12,\n",
       "                                                                           12),\n",
       "                                                       learning_rate='adaptive',\n",
       "                                                       random_state=1))]),\n",
       "              n_jobs=2, scoring='roc_auc',\n",
       "              search_spaces={'tfidf__max_df': array([0.3]),\n",
       "                             'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"MLP\",  MLPClassifier(\n",
    "        random_state=1,\n",
    "        solver=\"adam\",\n",
    "        hidden_layer_sizes=(12, 12, 12),\n",
    "        activation=\"relu\",\n",
    "        early_stopping=True,\n",
    "        alpha=0.0001,\n",
    "        learning_rate= 'adaptive',\n",
    "    ))])\n",
    "\n",
    "# define parameter space to test\n",
    "params = {\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "}\n",
    "\n",
    "pipe_MLP_Bayes = BayesSearchCV(\n",
    "    pipe, params, cv=pds, verbose=1, n_jobs=2, scoring='roc_auc')\n",
    "\n",
    "# fit the pipeline\n",
    "pipe_MLP_Bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "nhRnKsneYtsl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('tfidf__max_df', 0.3), ('tfidf__min_df', 7)])\n"
     ]
    }
   ],
   "source": [
    "best_params_MLP_Bayes = pipe_MLP_Bayes.best_params_\n",
    "print(best_params_MLP_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "BvL1mDyZY058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85      5151\n",
      "           1       0.81      0.86      0.83      4412\n",
      "\n",
      "    accuracy                           0.84      9563\n",
      "   macro avg       0.84      0.84      0.84      9563\n",
      "weighted avg       0.84      0.84      0.84      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_MLP_Bayes).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEURCk7OY9Dl"
   },
   "outputs": [],
   "source": [
    "# Use this cell to write the result in the excel sheet.\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['id'] = test_data['id']\n",
    "\n",
    "submission['label'] = pipe_MLP_Bayes.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission.to_csv('trial04_MLP_Bayes_word_clean_91.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Word-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using MLPClassifier with Bayse Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 84%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * min_df: 7\n",
    "  * max_df: 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lfNmqi2fQM6"
   },
   "source": [
    "### Model#5 Random forest with Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Prggn1GSZZy8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;Rand&#x27;,\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;Rand__max_depth&#x27;: [70, 80, 90],\n",
       "                                        &#x27;Rand__max_features&#x27;: [10, 20, 30],\n",
       "                                        &#x27;Rand__n_estimators&#x27;: [170, 200, 250],\n",
       "                                        &#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                             (&#x27;Rand&#x27;,\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;Rand__max_depth&#x27;: [70, 80, 90],\n",
       "                                        &#x27;Rand__max_features&#x27;: [10, 20, 30],\n",
       "                                        &#x27;Rand__n_estimators&#x27;: [170, 200, 250],\n",
       "                                        &#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;Rand&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                             ('Rand',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'Rand__max_depth': [70, 80, 90],\n",
       "                                        'Rand__max_features': [10, 20, 30],\n",
       "                                        'Rand__n_estimators': [170, 200, 250],\n",
       "                                        'tfidf__max_df': array([0.3]),\n",
       "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"Rand\",  RandomForestClassifier())])\n",
    "# define parameter space to test\n",
    "params = {\n",
    "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "    'Rand__n_estimators': [170,200,250],\n",
    "    'Rand__max_depth':[70,80,90],   \n",
    "    'Rand__max_features':[10,20,30]\n",
    "}\n",
    "\n",
    "pipe_Rand_Ran = RandomizedSearchCV(pipe, params, cv=pds, n_jobs=-1,\n",
    "                                   scoring='roc_auc', n_iter=10)\n",
    "pipe_Rand_Ran.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "qJUICe25iEWZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 7, 'tfidf__max_df': 0.3, 'Rand__n_estimators': 200, 'Rand__max_features': 30, 'Rand__max_depth': 90}\n"
     ]
    }
   ],
   "source": [
    "best_params_Rand_Ran = pipe_Rand_Ran.best_params_\n",
    "print(best_params_Rand_Ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "LgT7UMSjiGeD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      5151\n",
      "           1       0.99      0.83      0.90      4412\n",
      "\n",
      "    accuracy                           0.91      9563\n",
      "   macro avg       0.93      0.91      0.91      9563\n",
      "weighted avg       0.92      0.91      0.91      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_Rand_Ran).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ai9al15uz2j_"
   },
   "outputs": [],
   "source": [
    "# Use this cell to write the result in the excel sheet.\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['id'] = test_data['id']\n",
    "\n",
    "submission['label'] = pipe_Rand_Ran.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission.to_csv('trial05_RandomF_RandomC_word_clean_94.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Word-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using Random Forest Classifier with Random Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 91%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * ngram_range: (1, 3)\n",
    "  * min_df: 7\n",
    "  * max_df: 0.3\n",
    "  * n_estimators: 200\n",
    "  * max_features: 30\n",
    "  * max_depth: 90\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaIkzZTSyAif"
   },
   "source": [
    "### Model#6 Random forest with Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "kDiALj-6xp2n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                        (&#x27;Rand&#x27;, RandomForestClassifier())]),\n",
       "              n_iter=10, n_jobs=-1, scoring=&#x27;roc_auc&#x27;,\n",
       "              search_spaces={&#x27;Rand__max_depth&#x27;: [70, 80, 90],\n",
       "                             &#x27;Rand__max_features&#x27;: [10, 20, 30],\n",
       "                             &#x27;Rand__n_estimators&#x27;: [170, 200, 250],\n",
       "                             &#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                        (&#x27;Rand&#x27;, RandomForestClassifier())]),\n",
       "              n_iter=10, n_jobs=-1, scoring=&#x27;roc_auc&#x27;,\n",
       "              search_spaces={&#x27;Rand__max_depth&#x27;: [70, 80, 90],\n",
       "                             &#x27;Rand__max_features&#x27;: [10, 20, 30],\n",
       "                             &#x27;Rand__n_estimators&#x27;: [170, 200, 250],\n",
       "                             &#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;Rand&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                        ('Rand', RandomForestClassifier())]),\n",
       "              n_iter=10, n_jobs=-1, scoring='roc_auc',\n",
       "              search_spaces={'Rand__max_depth': [70, 80, 90],\n",
       "                             'Rand__max_features': [10, 20, 30],\n",
       "                             'Rand__n_estimators': [170, 200, 250],\n",
       "                             'tfidf__max_df': array([0.3]),\n",
       "                             'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"Rand\",  RandomForestClassifier())])\n",
    "# define parameter space to test\n",
    "params = {\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "    'Rand__n_estimators': [170,200,250],\n",
    "    'Rand__max_depth':[70,80,90],   \n",
    "    'Rand__max_features':[10,20,30]\n",
    "}\n",
    "\n",
    "pipe_Rand_Bayes = BayesSearchCV(pipe, params, cv=pds, n_jobs=-1,\n",
    "                                   scoring='roc_auc', n_iter=10)\n",
    "pipe_Rand_Bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "TCorS_sSx31H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 7, 'tfidf__max_df': 0.3, 'Rand__n_estimators': 200, 'Rand__max_features': 30, 'Rand__max_depth': 90}\n"
     ]
    }
   ],
   "source": [
    "best_params_Rand_Bayes = pipe_Rand_Ran.best_params_\n",
    "print(best_params_Rand_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "TekEJ2yMx5cZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      5151\n",
      "           1       0.99      0.81      0.89      4412\n",
      "\n",
      "    accuracy                           0.91      9563\n",
      "   macro avg       0.92      0.90      0.90      9563\n",
      "weighted avg       0.92      0.91      0.90      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_Rand_Bayes).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N201CXe7zfwf"
   },
   "outputs": [],
   "source": [
    "# Use this cell to write the result in the excel sheet.\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['id'] = test_data['id']\n",
    "\n",
    "submission['label'] = pipe_Rand_Bayes.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission.to_csv('trial06_RandomF_Bayes_word_clean_96.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Word-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using Random Forest Classifier with Bayse Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 91%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * ngram_range: (1, 3)\n",
    "  * min_df: 7\n",
    "  * max_df: 0.3\n",
    "  * n_estimators: 200\n",
    "  * max_features: 30\n",
    "  * max_depth: 90\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pq_Q6puk2Dx4"
   },
   "source": [
    "## II Character-Level Victorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUTVyJZA_zP-"
   },
   "source": [
    "### Model#7 XGB with Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "IdWulVOK_zP_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                              TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                             (&#x27;XGB&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature...\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                              TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                             (&#x27;XGB&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature...\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                (&#x27;XGB&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(analyzer='char')),\n",
       "                                             ('XGB',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature...\n",
       "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", norm=\"l2\")), (\"XGB\", XGBClassifier())])\n",
    "\n",
    "# define parameter space to test # runtime 35min\n",
    "params = {\n",
    "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "}\n",
    "pipe_XGB_Random = RandomizedSearchCV(\n",
    "    pipe, params, cv=pds, n_jobs=-1, scoring='roc_auc', n_iter=10)\n",
    "pipe_XGB_Random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "2cm5Os9P_zP_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 6, 'tfidf__max_df': 0.3}\n"
     ]
    }
   ],
   "source": [
    "best_params_XGB_Random = pipe_XGB_Random.best_params_\n",
    "print(best_params_XGB_Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "iIPxlnxN_zP_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      5151\n",
      "           1       0.85      0.85      0.85      4412\n",
      "\n",
      "    accuracy                           0.86      9563\n",
      "   macro avg       0.86      0.86      0.86      9563\n",
      "weighted avg       0.86      0.86      0.86      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_XGB_Random).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Character-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using XGBClassifier with Random Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 86%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * ngram_range: (1, 3)\n",
    "  * min_df: 6\n",
    "  * max_df: 0.3\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUFNziR5AhDO"
   },
   "source": [
    "### Model#8 XGB with Bayes Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "RJEuffkUAhDO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                         TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                        (&#x27;XGB&#x27;,\n",
       "                                         XGBClassifier(base_score=None,\n",
       "                                                       booster=None,\n",
       "                                                       callbacks=None,\n",
       "                                                       colsample_bylevel=None,\n",
       "                                                       colsample_bynode=None,\n",
       "                                                       colsample_bytree=None,\n",
       "                                                       early_stopping_rounds=None,\n",
       "                                                       enable_categorical=False,\n",
       "                                                       eval_metric=None,\n",
       "                                                       feature_type...\n",
       "              search_spaces={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                         TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                        (&#x27;XGB&#x27;,\n",
       "                                         XGBClassifier(base_score=None,\n",
       "                                                       booster=None,\n",
       "                                                       callbacks=None,\n",
       "                                                       colsample_bylevel=None,\n",
       "                                                       colsample_bynode=None,\n",
       "                                                       colsample_bytree=None,\n",
       "                                                       early_stopping_rounds=None,\n",
       "                                                       enable_categorical=False,\n",
       "                                                       eval_metric=None,\n",
       "                                                       feature_type...\n",
       "              search_spaces={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                (&#x27;XGB&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[('tfidf',\n",
       "                                         TfidfVectorizer(analyzer='char')),\n",
       "                                        ('XGB',\n",
       "                                         XGBClassifier(base_score=None,\n",
       "                                                       booster=None,\n",
       "                                                       callbacks=None,\n",
       "                                                       colsample_bylevel=None,\n",
       "                                                       colsample_bynode=None,\n",
       "                                                       colsample_bytree=None,\n",
       "                                                       early_stopping_rounds=None,\n",
       "                                                       enable_categorical=False,\n",
       "                                                       eval_metric=None,\n",
       "                                                       feature_type...\n",
       "              search_spaces={'tfidf__max_df': array([0.3]),\n",
       "                             'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", norm=\"l2\")), (\"XGB\", XGBClassifier())])\n",
    "\n",
    "# define parameter space to test # runtime 35min\n",
    "params = {\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "}\n",
    "# it is quite slow so we do 4 for now\n",
    "pipe_XGB_Bayes = BayesSearchCV(\n",
    "    pipe, params, cv=pds, n_jobs=-1, scoring='roc_auc', n_iter=10)\n",
    "pipe_XGB_Bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "I1O1QklxAhDP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('tfidf__max_df', 0.3), ('tfidf__min_df', 32)])\n"
     ]
    }
   ],
   "source": [
    "best_params_XGB_Bayes = pipe_XGB_Bayes.best_params_\n",
    "print(best_params_XGB_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "-JqPZhohAhDP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70      5151\n",
      "           1       0.69      0.00      0.00      4412\n",
      "\n",
      "    accuracy                           0.54      9563\n",
      "   macro avg       0.61      0.50      0.35      9563\n",
      "weighted avg       0.61      0.54      0.38      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_XGB_Bayes).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fv4He7emAs9v"
   },
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Character-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using XGBClassifier with Bayse Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 54%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * min_df: 32\n",
    "  * max_df: 0.3\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp_PXjdqAtPO"
   },
   "source": [
    "### Model#9 MLP with Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "zfySLCb-AtPO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                              TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                             (&#x27;MLP&#x27;,\n",
       "                                              MLPClassifier(early_stopping=True,\n",
       "                                                            hidden_layer_sizes=(15,\n",
       "                                                                                15,\n",
       "                                                                                15),\n",
       "                                                            n_iter_no_change=1,\n",
       "                                                            random_state=1))]),\n",
       "                   n_jobs=2,\n",
       "                   param_distributions={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                              TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                             (&#x27;MLP&#x27;,\n",
       "                                              MLPClassifier(early_stopping=True,\n",
       "                                                            hidden_layer_sizes=(15,\n",
       "                                                                                15,\n",
       "                                                                                15),\n",
       "                                                            n_iter_no_change=1,\n",
       "                                                            random_state=1))]),\n",
       "                   n_jobs=2,\n",
       "                   param_distributions={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                                        &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        &#x27;tfidf__ngram_range&#x27;: [(1, 2), (1, 3)]},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                (&#x27;MLP&#x27;,\n",
       "                 MLPClassifier(early_stopping=True,\n",
       "                               hidden_layer_sizes=(15, 15, 15),\n",
       "                               n_iter_no_change=1, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(15, 15, 15),\n",
       "              n_iter_no_change=1, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(analyzer='char')),\n",
       "                                             ('MLP',\n",
       "                                              MLPClassifier(early_stopping=True,\n",
       "                                                            hidden_layer_sizes=(15,\n",
       "                                                                                15,\n",
       "                                                                                15),\n",
       "                                                            n_iter_no_change=1,\n",
       "                                                            random_state=1))]),\n",
       "                   n_jobs=2,\n",
       "                   param_distributions={'tfidf__max_df': array([0.3]),\n",
       "                                        'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
       "                   scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", norm=\"l2\")), (\"MLP\",  MLPClassifier(\n",
    "        random_state=1,\n",
    "        solver=\"adam\",\n",
    "        hidden_layer_sizes=(15, 15, 15),\n",
    "        activation=\"relu\",\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=1,\n",
    "    ))])\n",
    "\n",
    "# define parameter space to test\n",
    "params = {\n",
    "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "}\n",
    "\n",
    "pipe_MLP_Random = RandomizedSearchCV(\n",
    "    pipe, params, cv=pds, verbose=1, n_jobs=2, scoring='roc_auc')\n",
    "\n",
    "# fit the pipeline\n",
    "pipe_MLP_Random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "tjpwJNHrAtPO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 55, 'tfidf__max_df': 0.3}\n"
     ]
    }
   ],
   "source": [
    "best_params_MLP_Random = pipe_MLP_Random.best_params_\n",
    "print(best_params_MLP_Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "1TJu5jO-AtPO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      5151\n",
      "           1       0.75      0.78      0.76      4412\n",
      "\n",
      "    accuracy                           0.78      9563\n",
      "   macro avg       0.78      0.78      0.78      9563\n",
      "weighted avg       0.78      0.78      0.78      9563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_MLP_Random).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Character-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using MLPClassifier with Random Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 78%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * ngram_range: (1, 3)\n",
    "  * min_df: 55\n",
    "  * max_df: 0.3\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnjQiFNWA2fP"
   },
   "source": [
    "### Model#10 MLP with Bayes Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "wNigDTDoA2fP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                         TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                        (&#x27;MLP&#x27;,\n",
       "                                         MLPClassifier(early_stopping=True,\n",
       "                                                       hidden_layer_sizes=(12,\n",
       "                                                                           12,\n",
       "                                                                           12),\n",
       "                                                       n_iter_no_change=1,\n",
       "                                                       random_state=1))]),\n",
       "              n_jobs=2, scoring=&#x27;roc_auc&#x27;,\n",
       "              search_spaces={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                         TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                        (&#x27;MLP&#x27;,\n",
       "                                         MLPClassifier(early_stopping=True,\n",
       "                                                       hidden_layer_sizes=(12,\n",
       "                                                                           12,\n",
       "                                                                           12),\n",
       "                                                       n_iter_no_change=1,\n",
       "                                                       random_state=1))]),\n",
       "              n_jobs=2, scoring=&#x27;roc_auc&#x27;,\n",
       "              search_spaces={&#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                (&#x27;MLP&#x27;,\n",
       "                 MLPClassifier(early_stopping=True,\n",
       "                               hidden_layer_sizes=(12, 12, 12),\n",
       "                               n_iter_no_change=1, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 12, 12),\n",
       "              n_iter_no_change=1, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[('tfidf',\n",
       "                                         TfidfVectorizer(analyzer='char')),\n",
       "                                        ('MLP',\n",
       "                                         MLPClassifier(early_stopping=True,\n",
       "                                                       hidden_layer_sizes=(12,\n",
       "                                                                           12,\n",
       "                                                                           12),\n",
       "                                                       n_iter_no_change=1,\n",
       "                                                       random_state=1))]),\n",
       "              n_jobs=2, scoring='roc_auc',\n",
       "              search_spaces={'tfidf__max_df': array([0.3]),\n",
       "                             'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", norm=\"l2\")), (\"MLP\",  MLPClassifier(\n",
    "        random_state=1,\n",
    "        solver=\"adam\",\n",
    "        hidden_layer_sizes=(12, 12, 12),\n",
    "        activation=\"relu\",\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=1,\n",
    "    ))])\n",
    "\n",
    "# define parameter space to test\n",
    "params = {\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "}\n",
    "\n",
    "pipe_MLP_Bayes = BayesSearchCV(\n",
    "    pipe, params, cv=pds, verbose=1, n_jobs=2, scoring='roc_auc')\n",
    "\n",
    "# fit the pipeline\n",
    "pipe_MLP_Bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "xuuP6nMSA2fP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('tfidf__max_df', 0.3), ('tfidf__min_df', 76)])\n"
     ]
    }
   ],
   "source": [
    "best_params_MLP_Bayes = pipe_MLP_Bayes.best_params_\n",
    "print(best_params_MLP_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "RTHxy6XyA2fP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70      5151\n",
      "           1       0.00      0.00      0.00      4412\n",
      "\n",
      "    accuracy                           0.54      9563\n",
      "   macro avg       0.27      0.50      0.35      9563\n",
      "weighted avg       0.29      0.54      0.38      9563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_MLP_Bayes).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nrg8j9l2Bnme"
   },
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Character-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using MLPClassifier with Bayse Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 54%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * min_df: 76\n",
    "  * max_df: 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BUYLxpKg12p"
   },
   "source": [
    "### Model#11 Logistic Regression with Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "VpwAJOHXhMK3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                         TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                        (&#x27;logreg&#x27;, LogisticRegression())]),\n",
       "              n_jobs=2, scoring=&#x27;roc_auc&#x27;,\n",
       "              search_spaces={&#x27;logreg__C&#x27;: [100, 200, 300],\n",
       "                             &#x27;logreg__max_iter&#x27;: [100, 200, 300],\n",
       "                             &#x27;logreg__tol&#x27;: [0.0001, 1e-05, 0.001],\n",
       "                             &#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                         TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                                        (&#x27;logreg&#x27;, LogisticRegression())]),\n",
       "              n_jobs=2, scoring=&#x27;roc_auc&#x27;,\n",
       "              search_spaces={&#x27;logreg__C&#x27;: [100, 200, 300],\n",
       "                             &#x27;logreg__max_iter&#x27;: [100, 200, 300],\n",
       "                             &#x27;logreg__tol&#x27;: [0.0001, 1e-05, 0.001],\n",
       "                             &#x27;tfidf__max_df&#x27;: array([0.3]),\n",
       "                             &#x27;tfidf__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;)),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
       "              estimator=Pipeline(steps=[('tfidf',\n",
       "                                         TfidfVectorizer(analyzer='char')),\n",
       "                                        ('logreg', LogisticRegression())]),\n",
       "              n_jobs=2, scoring='roc_auc',\n",
       "              search_spaces={'logreg__C': [100, 200, 300],\n",
       "                             'logreg__max_iter': [100, 200, 300],\n",
       "                             'logreg__tol': [0.0001, 1e-05, 0.001],\n",
       "                             'tfidf__max_df': array([0.3]),\n",
       "                             'tfidf__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", norm=\"l2\")), (\"logreg\",  LogisticRegression())])\n",
    "\n",
    "# define parameter space to test\n",
    "params = {\n",
    "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
    "    \"tfidf__min_df\": np.arange(5, 100),\n",
    "    'logreg__C': [100,200,300],\n",
    "    'logreg__max_iter':[100 ,200, 300], \n",
    "    'logreg__tol':[1e-4,1e-5,1e-3]\n",
    "\n",
    "}\n",
    "\n",
    "pipe_Logreg_Bayes = BayesSearchCV(\n",
    "    pipe, params, cv=pds, verbose=1, n_jobs=2, scoring='roc_auc')\n",
    "\n",
    "# fit the pipeline\n",
    "pipe_Logreg_Bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "igyRM6gVhw5i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('logreg__C', 200), ('logreg__max_iter', 200), ('logreg__tol', 1e-05), ('tfidf__max_df', 0.3), ('tfidf__min_df', 69)])\n"
     ]
    }
   ],
   "source": [
    "best_params_Logreg_Bayes = pipe_Logreg_Bayes.best_params_\n",
    "print(best_params_Logreg_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "TtxX7vn_h6BZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70      5151\n",
      "           1       0.00      0.00      0.00      4412\n",
      "\n",
      "    accuracy                           0.54      9563\n",
      "   macro avg       0.27      0.50      0.35      9563\n",
      "weighted avg       0.29      0.54      0.38      9563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lap1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params_Logreg_Bayes).fit(X_train, y_train)\n",
    "pipe_pred = pipe.predict(X_val)\n",
    "report = sklearn.metrics.classification_report(y_val, pipe_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **OBSERVATION**\n",
    "\n",
    "♦ If we work on Character-Level Victorizer,Using:\n",
    "\n",
    " 👉🏻 Using MLPClassifier with Bayse Search\n",
    "\n",
    "♦ we may find that:\n",
    "\n",
    "  👉🏻  ROC_AUC will be 54%\n",
    "  \n",
    "  ♦ and the best parameters will be:\n",
    "  \n",
    "  * ngram_range: (1, 3)\n",
    "  * min_df: 55\n",
    "  * max_df: 0.3\n",
    "  * C: 200\n",
    "  * max_iter: 200\n",
    "  * tol: 1e-05\n",
    "  * max_df: 0.3\n",
    "  * min_df: 69\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚫ **GENERAL OBSERVATION**\n",
    "\n",
    "♦ If we notice in all trials that :\n",
    "\n",
    " 👉🏻 Using Random Forest Classifier is the best classifier used in all of trials \n",
    " \n",
    " 👉 Using Bayse Search is the best serching algorithems that used in all trials\n",
    " \n",
    " 👉 Using Word-Level Verctorizer is more accurate of using Charachter-Level Vectorizer\n",
    "\n",
    "♦ Therefore, we can conclude from this Notebook in general that: \n",
    " \n",
    " 👉🏻 Using Random Forest Classifier with Bayse Search with Word-Level Verctorizer is the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jT2Ms7jE3HpP"
   },
   "source": [
    "# **Part II: Answering Questions** 😃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16U4goiIEB86"
   },
   "source": [
    "## 🌈 **Q1:** What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?\n",
    "\n",
    "⭐ Character n-grams and word n-grams are two commonly used techniques in NLP for feature extraction and text representation.\n",
    "\n",
    " Character n-grams involve extracting sequences of n consecutive characters from a text document. For example, if n = 3, the character n-grams for the word \"cat\" would be \"cat\", \"at\", and \"t\". Character n-grams can capture information about word morphology and spelling, and can be useful in tasks such as authorship attribution and language identification.\n",
    "\n",
    "⭐ Word n-grams, on the other hand, involve extracting sequences of n consecutive words from a text document. For example, if n = 2, the word n-grams for the sentence \"the quick brown fox\" would be \"the quick\", \"quick brown\", and \"brown fox\". Word n-grams can capture information about the context and meaning of words, and can be useful in tasks such as sentiment analysis and topic modeling.\n",
    "\n",
    "🔥 Both techniques can suffer from the OOV (Out Of Vocabulary) issue, where new or rare words are not present in the training data and therefore not represented by the n-grams. However, word n-grams tend to suffer more from the OOV issue, as they rely on a finite vocabulary of known words. This means that new or rare words that are not present in the vocabulary may not be correctly represented by the n-grams, and their meaning may be lost.\n",
    "\n",
    "🔥 Character n-grams, on the other hand, are less affected by the OOV issue, as they can capture information about the morphology and spelling of new or rare words even if the specific word is not present in the training data. However, character n-grams may be less effective in tasks that require understanding of the meaning and context of words, as they do not capture information about word semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfoB41z7WZzy"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0P9ynrJTPtq"
   },
   "source": [
    "## 🌈 **Q2:**  What is the difference between stop word removal and stemming? Are these techniques language-dependent?\n",
    "\n",
    "☘️  Stop word removal and stemming are two common techniques used in natural language processing (NLP) for text preprocessing.\n",
    "\n",
    "☘️  Stop word removal involves removing common words that do not carry much meaning or contribute to the overall understanding of the text. Examples of stop words in English include \"the\", \"a\", \"an\", \"and\", \"in\", \"of\", and \"to\". By removing these words, the remaining words in the text can be more informative and relevant to the task at hand, such as sentiment analysis or topic modeling.\n",
    "\n",
    "☘️ Stemming, on the other hand, involves reducing words to their base or root form by removing suffixes and prefixes. For example, the stem of the word \"jumping\" is \"jump\", and the stem of the word \"dogs\" is \"dog\". Stemming can reduce the number of unique words in a text and can help to capture the core meaning of words, even if they are inflected or have different forms.\n",
    "\n",
    "🔥 Both techniques are language-dependent, as the stop words and stemming rules vary across different languages. For example, the English stop words mentioned above may not be relevant or applicable to other languages such as Chinese or Arabic. Similarly, the stemming rules for English may not be suitable for other languages that have different grammar rules and morphological structures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch9zBza8WbrK"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rrfiP9RU5vD"
   },
   "source": [
    "## 🌈 **Q3:**  Is tokenization techniques language dependent? Why?\n",
    "\n",
    "⭐ Tokenization is the process of breaking text into individual words or tokens. The tokenization techniques can be language-dependent, as different languages have different rules and conventions for word boundaries and sentence structure.\n",
    "\n",
    "⭐ For example, in English, words are generally separated by spaces, making it relatively easy to tokenize text based on whitespace. However, languages such as Chinese and Japanese do not use spaces between words, making it more challenging to determine the word boundaries. Tokenizing these languages requires more sophisticated techniques, such as word segmentation algorithms that use statistical models or machine learning to predict the most likely word boundaries.\n",
    "Therefore, it is important to consider the language of the text when selecting a tokenization technique. Using the wrong technique can lead to incorrect or incomplete tokenization, which can negatively impact downstream NLP tasks such as named entity recognition or part-of-speech tagging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YK_SC_xeWd66"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ4OdebaV2r0"
   },
   "source": [
    "## 🌈 **Q4:**  What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?\n",
    "\n",
    "☘️ Count vectorizer and tf-idf vectorizer are two commonly used techniques in natural language processing for converting raw text data into numerical vector representations that can be used as input to machine learning algorithms.\n",
    "\n",
    "☘️ Count vectorizer represents each text document as a vector of word counts, where each element in the vector corresponds to the count of a specific word in the document. For example, if a document contains the words \"cat\", \"dog\", and \"cat\", the count vector representation would be [2, 1, 0], indicating two occurrences of \"cat\", one occurrence of \"dog\", and zero occurrences of any other words.\n",
    "\n",
    "☘️ TF-IDF vectorizer, on the other hand, represents each text document as a vector of TF-IDF scores, where each element in the vector corresponds to the TF-IDF score of a specific word in the document. TF-IDF stands for Term Frequency-Inverse Document Frequency, which is a measure of how important a word is to a document in a collection of documents. The TF-IDF score is calculated by multiplying the term frequency (TF) of a word in a document by the inverse document frequency (IDF) of the word across all documents in the collection.\n",
    "\n",
    "☘️ Regarding the use of all possible n-grams, it may not be feasible to use all possible n-grams, especially for larger values of n, as the number of possible n-grams can become very large and this can lead to the curse of dimensionality. In practice, it is commonto limit the maximum number of n-grams used in the vectorization process to a reasonable number, based on the size of the dataset and the computational resources available.\n",
    "\n",
    "☘️ To select the appropriate n-grams, it is important to consider the specific task and the characteristics of the dataset. For example, if the task involves sentiment analysis, it may be useful to include unigrams and bigrams that capture sentiment-related words such as \"good\" or \"bad\", while excluding other n-grams that may not be relevant to the task. Additionally, it may be useful to experiment with different n-gram configurations and compare their performance to determine the optimal n-gram range for a specific task and dataset.\n",
    "\n",
    "☘️ Some common strategies for selecting n-grams include using domain knowledge or external resources to identify relevant n-grams, using feature selection techniques to identify the most informative n-grams based on their correlation with the target variable, or using grid search or other optimization methods to find the optimal n-gram range for a specific task and dataset."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
